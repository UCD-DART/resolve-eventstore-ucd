{"version":3,"sources":["../../src/js/begin-incremental-import.js"],"names":["beginIncrementalImport","executeStatement","databaseName","eventsTableName","escapeId","escape","databaseNameAsId","incrementalImportTableAsId","importId","Buffer","from","Date","now","Math","random","toString","replace","LONG_NUMBER_SQL_TYPE","BIG_SERIAL","INT8_SQL_TYPE","LONG_STRING_SQL_TYPE","JSON_SQL_TYPE","error","test","message","Error"],"mappings":";;;;;;;AAAA;;AAQA,MAAMA,sBAAsB,GAAG,OAAO;AACpCC,EAAAA,gBADoC;AAEpCC,EAAAA,YAFoC;AAGpCC,EAAAA,eAHoC;AAIpCC,EAAAA,QAJoC;AAKpCC,EAAAA;AALoC,CAAP,KAMzB;AACJ,MAAI;AACF,UAAMC,gBAAgB,GAAGF,QAAQ,CAACF,YAAD,CAAjC;AACA,UAAMK,0BAA0B,GAAGH,QAAQ,CACxC,GAAED,eAAgB,qBADsB,CAA3C;AAGA,UAAMK,QAAQ,GAAGC,MAAM,CAACC,IAAP,CAAa,GAAEC,IAAI,CAACC,GAAL,EAAW,GAAEC,IAAI,CAACC,MAAL,EAAc,EAA1C,EACdC,QADc,CACL,QADK,EAEdC,OAFc,CAEN,WAFM,EAEO,GAFP,CAAjB;AAGA,UAAMf,gBAAgB,CACnB,gBAAeK,gBAAiB,IAAGC,0BAA2B;AACrE,sBAAsBU,+BAAqB;AAC3C,kBAAkBC,qBAAW;AAC7B,qBAAqBD,+BAAqB;AAC1C,0BAA0BE,wBAAc;AACxC,sBAAsBF,+BAAqB;AAC3C,wBAAwBG,+BAAqB;AAC7C,6BAA6BH,+BAAqB;AAClD,iBAAiBG,+BAAqB;AACtC,oBAAoBC,wBAAc;AAClC,sBAAsBJ,+BAAqB;AAC3C;AACA;AACA,yBAAyBX,gBAAiB,IAAGC,0BAA2B;AACxE,WAAWF,MAAM,CACR,8BAA6BA,MAAM,CAACG,QAAD,CAAW,cADtC,CAET;AACR,OAlB0B,CAAtB;AAqBA,WAAOA,QAAP;AACD,GA9BD,CA8BE,OAAOc,KAAP,EAAc;AACd,QAAIA,KAAK,IAAI,IAAT,IAAiB,+BAA+BC,IAA/B,CAAoCD,KAAK,CAACE,OAA1C,CAArB,EAAyE;AACvE,YAAM,IAAIC,KAAJ,CAAW,6CAAX,CAAN;AACD,KAFD,MAEO;AACL,YAAMH,KAAN;AACD;AACF;AACF,CA5CD;;eA8CetB,sB","sourcesContent":["import {\n  LONG_STRING_SQL_TYPE,\n  LONG_NUMBER_SQL_TYPE,\n  INT8_SQL_TYPE,\n  JSON_SQL_TYPE,\n  BIG_SERIAL,\n} from './constants'\n\nconst beginIncrementalImport = async ({\n  executeStatement,\n  databaseName,\n  eventsTableName,\n  escapeId,\n  escape,\n}) => {\n  try {\n    const databaseNameAsId = escapeId(databaseName)\n    const incrementalImportTableAsId = escapeId(\n      `${eventsTableName}-incremental-import`\n    )\n    const importId = Buffer.from(`${Date.now()}${Math.random()}`)\n      .toString('base64')\n      .replace(/\\/|\\+|=/gi, 'z')\n    await executeStatement(\n      `CREATE TABLE ${databaseNameAsId}.${incrementalImportTableAsId}(\n        \"sortedIdx\" ${LONG_NUMBER_SQL_TYPE} NULL,\n        \"rowid\" ${BIG_SERIAL},\n        \"threadId\" ${LONG_NUMBER_SQL_TYPE} NULL,\n        \"threadCounter\" ${INT8_SQL_TYPE} NULL,\n        \"timestamp\" ${LONG_NUMBER_SQL_TYPE} NOT NULL,\n        \"aggregateId\" ${LONG_STRING_SQL_TYPE} NOT NULL,\n        \"aggregateVersion\" ${LONG_NUMBER_SQL_TYPE} NULL,\n        \"type\" ${LONG_STRING_SQL_TYPE} NOT NULL,\n        \"payload\" ${JSON_SQL_TYPE},\n        \"eventSize\" ${LONG_NUMBER_SQL_TYPE} NOT NULL\n      );\n      \n      COMMENT ON TABLE ${databaseNameAsId}.${incrementalImportTableAsId}\n      IS ${escape(\n        `RESOLVE INCREMENTAL-IMPORT ${escape(importId)} OWNED TABLE`\n      )};\n      `\n    )\n\n    return importId\n  } catch (error) {\n    if (error != null && /Relation.*? already exists$/i.test(error.message)) {\n      throw new Error(`Previous incremental import is not finished`)\n    } else {\n      throw error\n    }\n  }\n}\n\nexport default beginIncrementalImport\n"],"file":"begin-incremental-import.js"}